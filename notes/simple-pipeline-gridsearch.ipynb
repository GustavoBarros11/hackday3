{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223d8b72",
   "metadata": {
    "papermill": {
     "duration": 0.010247,
     "end_time": "2022-06-03T02:54:52.777220",
     "exception": false,
     "start_time": "2022-06-03T02:54:52.766973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59634db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:52.798055Z",
     "iopub.status.busy": "2022-06-03T02:54:52.797342Z",
     "iopub.status.idle": "2022-06-03T02:54:54.429862Z",
     "shell.execute_reply": "2022-06-03T02:54:54.428864Z"
    },
    "papermill": {
     "duration": 1.645749,
     "end_time": "2022-06-03T02:54:54.432476",
     "exception": false,
     "start_time": "2022-06-03T02:54:52.786727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder,StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50203a26",
   "metadata": {
    "papermill": {
     "duration": 0.00922,
     "end_time": "2022-06-03T02:54:54.451936",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.442716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2.0. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d208f354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.472978Z",
     "iopub.status.busy": "2022-06-03T02:54:54.472367Z",
     "iopub.status.idle": "2022-06-03T02:54:54.568191Z",
     "shell.execute_reply": "2022-06-03T02:54:54.567193Z"
    },
    "papermill": {
     "duration": 0.109135,
     "end_time": "2022-06-03T02:54:54.570801",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.461666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>uid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>uniqueid_4858</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Divorced/Seperated</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "      <td>Rwanda_uniqueid_4858</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>2017</td>\n",
       "      <td>uniqueid_3015</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>Tanzania_uniqueid_3015</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>uniqueid_103</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "      <td>Rwanda_uniqueid_103</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>uniqueid_4582</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "      <td>Rwanda_uniqueid_4582</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>2017</td>\n",
       "      <td>uniqueid_2854</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "      <td>Tanzania_uniqueid_2854</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  year       uniqueid location_type cellphone_access  \\\n",
       "0    Rwanda  2016  uniqueid_4858         Rural              Yes   \n",
       "1  Tanzania  2017  uniqueid_3015         Urban               No   \n",
       "2    Rwanda  2016   uniqueid_103         Rural              Yes   \n",
       "3    Rwanda  2016  uniqueid_4582         Rural               No   \n",
       "4  Tanzania  2017  uniqueid_2854         Urban              Yes   \n",
       "\n",
       "   household_size  age_of_respondent gender_of_respondent  \\\n",
       "0               6                 45                 Male   \n",
       "1               4                 33               Female   \n",
       "2               7                 43                 Male   \n",
       "3               6                 35               Female   \n",
       "4               2                 30                 Male   \n",
       "\n",
       "  relationship_with_head           marital_status      education_level  \\\n",
       "0      Head of Household       Divorced/Seperated    Primary education   \n",
       "1      Head of Household     Single/Never Married    Primary education   \n",
       "2      Head of Household  Married/Living together  Secondary education   \n",
       "3      Head of Household  Married/Living together    Primary education   \n",
       "4      Head of Household     Single/Never Married    Primary education   \n",
       "\n",
       "              job_type                     uid bank_account  \n",
       "0  Farming and Fishing    Rwanda_uniqueid_4858           No  \n",
       "1        Self employed  Tanzania_uniqueid_3015           No  \n",
       "2  Farming and Fishing     Rwanda_uniqueid_103           No  \n",
       "3  Farming and Fishing    Rwanda_uniqueid_4582           No  \n",
       "4  Informally employed  Tanzania_uniqueid_2854           No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/inclusao-financeira-na-africa/train.csv')\n",
    "data.head()\n",
    "# household / age / gender / cellphone / education_level / job_type = DEIXAR\n",
    "# marital status / relationship with head? / country? /  location_type? / year?  = TIRAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8281ea",
   "metadata": {
    "papermill": {
     "duration": 0.009338,
     "end_time": "2022-06-03T02:54:54.590314",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.580976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3.0. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db08fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.612175Z",
     "iopub.status.busy": "2022-06-03T02:54:54.611720Z",
     "iopub.status.idle": "2022-06-03T02:54:54.646967Z",
     "shell.execute_reply": "2022-06-03T02:54:54.645919Z"
    },
    "papermill": {
     "duration": 0.048743,
     "end_time": "2022-06-03T02:54:54.649429",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.600686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11762.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016.983336</td>\n",
       "      <td>3.793913</td>\n",
       "      <td>38.602364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.848669</td>\n",
       "      <td>2.225423</td>\n",
       "      <td>16.334624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year  household_size  age_of_respondent\n",
       "count  11762.000000    11762.000000       11762.000000\n",
       "mean    2016.983336        3.793913          38.602364\n",
       "std        0.848669        2.225423          16.334624\n",
       "min     2016.000000        1.000000          16.000000\n",
       "25%     2016.000000        2.000000          26.000000\n",
       "50%     2017.000000        3.000000          35.000000\n",
       "75%     2018.000000        5.000000          48.000000\n",
       "max     2018.000000       21.000000         100.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77c30f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.671879Z",
     "iopub.status.busy": "2022-06-03T02:54:54.670921Z",
     "iopub.status.idle": "2022-06-03T02:54:54.694052Z",
     "shell.execute_reply": "2022-06-03T02:54:54.693007Z"
    },
    "papermill": {
     "duration": 0.036478,
     "end_time": "2022-06-03T02:54:54.696233",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.659755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                   0\n",
       "year                      0\n",
       "uniqueid                  0\n",
       "location_type             0\n",
       "cellphone_access          0\n",
       "household_size            0\n",
       "age_of_respondent         0\n",
       "gender_of_respondent      0\n",
       "relationship_with_head    0\n",
       "marital_status            0\n",
       "education_level           0\n",
       "job_type                  0\n",
       "uid                       0\n",
       "bank_account              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6589d7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.717957Z",
     "iopub.status.busy": "2022-06-03T02:54:54.717244Z",
     "iopub.status.idle": "2022-06-03T02:54:54.725259Z",
     "shell.execute_reply": "2022-06-03T02:54:54.724261Z"
    },
    "papermill": {
     "duration": 0.021238,
     "end_time": "2022-06-03T02:54:54.727335",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.706097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                   object\n",
       "year                       int64\n",
       "uniqueid                  object\n",
       "location_type             object\n",
       "cellphone_access          object\n",
       "household_size             int64\n",
       "age_of_respondent          int64\n",
       "gender_of_respondent      object\n",
       "relationship_with_head    object\n",
       "marital_status            object\n",
       "education_level           object\n",
       "job_type                  object\n",
       "uid                       object\n",
       "bank_account              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e24002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.748874Z",
     "iopub.status.busy": "2022-06-03T02:54:54.748421Z",
     "iopub.status.idle": "2022-06-03T02:54:54.756184Z",
     "shell.execute_reply": "2022-06-03T02:54:54.755378Z"
    },
    "papermill": {
     "duration": 0.020869,
     "end_time": "2022-06-03T02:54:54.758128",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.737259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rural', 'Urban'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duas categorias - 2 colunas\n",
    "data.location_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e512ad90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.780405Z",
     "iopub.status.busy": "2022-06-03T02:54:54.779691Z",
     "iopub.status.idle": "2022-06-03T02:54:54.787295Z",
     "shell.execute_reply": "2022-06-03T02:54:54.786363Z"
    },
    "papermill": {
     "duration": 0.021125,
     "end_time": "2022-06-03T02:54:54.789264",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.768139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duas categorias\n",
    "data.cellphone_access.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8683b4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.811749Z",
     "iopub.status.busy": "2022-06-03T02:54:54.811071Z",
     "iopub.status.idle": "2022-06-03T02:54:54.818473Z",
     "shell.execute_reply": "2022-06-03T02:54:54.817689Z"
    },
    "papermill": {
     "duration": 0.020954,
     "end_time": "2022-06-03T02:54:54.820458",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.799504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duas categorias\n",
    "data.gender_of_respondent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b383450f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.843828Z",
     "iopub.status.busy": "2022-06-03T02:54:54.843060Z",
     "iopub.status.idle": "2022-06-03T02:54:54.851202Z",
     "shell.execute_reply": "2022-06-03T02:54:54.850311Z"
    },
    "papermill": {
     "duration": 0.022458,
     "end_time": "2022-06-03T02:54:54.853294",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.830836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Head of Household', 'Spouse', 'Child', 'Parent', 'Other relative',\n",
       "       'Other non-relatives'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 categorias - sem ordem\n",
    "data.relationship_with_head.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f8aa6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.877342Z",
     "iopub.status.busy": "2022-06-03T02:54:54.876601Z",
     "iopub.status.idle": "2022-06-03T02:54:54.884688Z",
     "shell.execute_reply": "2022-06-03T02:54:54.883675Z"
    },
    "papermill": {
     "duration": 0.022234,
     "end_time": "2022-06-03T02:54:54.886795",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.864561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Divorced/Seperated', 'Single/Never Married',\n",
       "       'Married/Living together', 'Widowed', 'Dont know'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 categorias - sem ordem\n",
    "data.marital_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1e357f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.911089Z",
     "iopub.status.busy": "2022-06-03T02:54:54.910657Z",
     "iopub.status.idle": "2022-06-03T02:54:54.918755Z",
     "shell.execute_reply": "2022-06-03T02:54:54.917785Z"
    },
    "papermill": {
     "duration": 0.022784,
     "end_time": "2022-06-03T02:54:54.920840",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.898056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Primary education', 'Secondary education',\n",
       "       'Vocational/Specialised training', 'Tertiary education',\n",
       "       'No formal education', 'Other/Dont know/RTA'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 categorias - com ordem \n",
    "data.education_level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85c7744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.944538Z",
     "iopub.status.busy": "2022-06-03T02:54:54.943805Z",
     "iopub.status.idle": "2022-06-03T02:54:54.951453Z",
     "shell.execute_reply": "2022-06-03T02:54:54.950690Z"
    },
    "papermill": {
     "duration": 0.021714,
     "end_time": "2022-06-03T02:54:54.953374",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.931660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Farming and Fishing', 'Self employed', 'Informally employed',\n",
       "       'No Income', 'Other Income', 'Remittance Dependent',\n",
       "       'Formally employed Private', 'Government Dependent',\n",
       "       'Dont Know/Refuse to answer', 'Formally employed Government'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 categorias - sem ordem\n",
    "data.job_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c497488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:54.978013Z",
     "iopub.status.busy": "2022-06-03T02:54:54.977300Z",
     "iopub.status.idle": "2022-06-03T02:54:54.987060Z",
     "shell.execute_reply": "2022-06-03T02:54:54.986041Z"
    },
    "papermill": {
     "duration": 0.024771,
     "end_time": "2022-06-03T02:54:54.989083",
     "exception": false,
     "start_time": "2022-06-03T02:54:54.964312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     10077\n",
       "Yes     1685\n",
       "Name: bank_account, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.bank_account.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a53a57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.013341Z",
     "iopub.status.busy": "2022-06-03T02:54:55.012640Z",
     "iopub.status.idle": "2022-06-03T02:54:55.029982Z",
     "shell.execute_reply": "2022-06-03T02:54:55.028666Z"
    },
    "papermill": {
     "duration": 0.033148,
     "end_time": "2022-06-03T02:54:55.033307",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.000159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self employed                   3207\n",
      "Informally employed             2788\n",
      "Farming and Fishing             2732\n",
      "Remittance Dependent            1252\n",
      "Other Income                     569\n",
      "Formally employed Private        514\n",
      "No Income                        310\n",
      "Formally employed Government     206\n",
      "Government Dependent             125\n",
      "Dont Know/Refuse to answer        59\n",
      "Name: job_type, dtype: int64\n",
      " \n",
      "Married/Living together    5433\n",
      "Single/Never Married       3970\n",
      "Widowed                    1321\n",
      "Divorced/Seperated         1034\n",
      "Dont know                     4\n",
      "Name: marital_status, dtype: int64\n",
      "\n",
      "Head of Household      6358\n",
      "Spouse                 3287\n",
      "Child                  1099\n",
      "Parent                  560\n",
      "Other relative          368\n",
      "Other non-relatives      90\n",
      "Name: relationship_with_head, dtype: int64\n",
      "\n",
      "Primary education                  6408\n",
      "No formal education                2240\n",
      "Secondary education                2129\n",
      "Tertiary education                  566\n",
      "Vocational/Specialised training     399\n",
      "Other/Dont know/RTA                  20\n",
      "Name: education_level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['job_type'].value_counts())\n",
    "print(' ')\n",
    "print(data['marital_status'].value_counts()) \n",
    "print('')\n",
    "print(data['relationship_with_head'].value_counts())\n",
    "print('')\n",
    "print(data['education_level'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca795dfe",
   "metadata": {
    "papermill": {
     "duration": 0.011333,
     "end_time": "2022-06-03T02:54:55.056234",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.044901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.0. Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "540e2be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.080240Z",
     "iopub.status.busy": "2022-06-03T02:54:55.079848Z",
     "iopub.status.idle": "2022-06-03T02:54:55.086306Z",
     "shell.execute_reply": "2022-06-03T02:54:55.085295Z"
    },
    "papermill": {
     "duration": 0.020886,
     "end_time": "2022-06-03T02:54:55.088354",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.067468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop id columns - irrelevant for the model\n",
    "data_dropped = data.drop(['uniqueid', 'uid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce7b72c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.113496Z",
     "iopub.status.busy": "2022-06-03T02:54:55.112681Z",
     "iopub.status.idle": "2022-06-03T02:54:55.119008Z",
     "shell.execute_reply": "2022-06-03T02:54:55.118304Z"
    },
    "papermill": {
     "duration": 0.020958,
     "end_time": "2022-06-03T02:54:55.121002",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.100044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separação de x e y \n",
    "X = data_dropped.iloc[:,0:11]\n",
    "y = data_dropped['bank_account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a07094e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.145607Z",
     "iopub.status.busy": "2022-06-03T02:54:55.145061Z",
     "iopub.status.idle": "2022-06-03T02:54:55.161440Z",
     "shell.execute_reply": "2022-06-03T02:54:55.160391Z"
    },
    "papermill": {
     "duration": 0.031109,
     "end_time": "2022-06-03T02:54:55.163428",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.132319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Divorced/Seperated</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>2017</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>2017</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  year location_type cellphone_access  household_size  \\\n",
       "0    Rwanda  2016         Rural              Yes               6   \n",
       "1  Tanzania  2017         Urban               No               4   \n",
       "2    Rwanda  2016         Rural              Yes               7   \n",
       "3    Rwanda  2016         Rural               No               6   \n",
       "4  Tanzania  2017         Urban              Yes               2   \n",
       "\n",
       "   age_of_respondent gender_of_respondent relationship_with_head  \\\n",
       "0                 45                 Male      Head of Household   \n",
       "1                 33               Female      Head of Household   \n",
       "2                 43                 Male      Head of Household   \n",
       "3                 35               Female      Head of Household   \n",
       "4                 30                 Male      Head of Household   \n",
       "\n",
       "            marital_status      education_level             job_type  \n",
       "0       Divorced/Seperated    Primary education  Farming and Fishing  \n",
       "1     Single/Never Married    Primary education        Self employed  \n",
       "2  Married/Living together  Secondary education  Farming and Fishing  \n",
       "3  Married/Living together    Primary education  Farming and Fishing  \n",
       "4     Single/Never Married    Primary education  Informally employed  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27479603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.188236Z",
     "iopub.status.busy": "2022-06-03T02:54:55.187387Z",
     "iopub.status.idle": "2022-06-03T02:54:55.216158Z",
     "shell.execute_reply": "2022-06-03T02:54:55.215185Z"
    },
    "papermill": {
     "duration": 0.043702,
     "end_time": "2022-06-03T02:54:55.218667",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.174965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stratified split - gera indexes\n",
    "# com o n_splits=1, possivelmente é mesma coisa que o train_test_split \n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=2187)\n",
    "\n",
    "for train_index, test_index in split.split(X,y):\n",
    "    X_train, X_val = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_val = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23579550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.243317Z",
     "iopub.status.busy": "2022-06-03T02:54:55.242923Z",
     "iopub.status.idle": "2022-06-03T02:54:55.258476Z",
     "shell.execute_reply": "2022-06-03T02:54:55.257856Z"
    },
    "papermill": {
     "duration": 0.030006,
     "end_time": "2022-06-03T02:54:55.260294",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.230288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Formally employed Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7951</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  year location_type cellphone_access  household_size  \\\n",
       "9120   Rwanda  2016         Urban              Yes               5   \n",
       "4584    Kenya  2018         Urban              Yes               1   \n",
       "10727  Rwanda  2016         Rural              Yes               2   \n",
       "7951   Rwanda  2016         Rural              Yes               6   \n",
       "3937   Rwanda  2016         Rural               No               5   \n",
       "\n",
       "       age_of_respondent gender_of_respondent relationship_with_head  \\\n",
       "9120                  48               Female                 Spouse   \n",
       "4584                  47               Female      Head of Household   \n",
       "10727                 35               Female                 Spouse   \n",
       "7951                  39               Female      Head of Household   \n",
       "3937                  44               Female                 Spouse   \n",
       "\n",
       "                marital_status      education_level  \\\n",
       "9120   Married/Living together  Secondary education   \n",
       "4584   Married/Living together  Secondary education   \n",
       "10727  Married/Living together    Primary education   \n",
       "7951                   Widowed    Primary education   \n",
       "3937   Married/Living together  No formal education   \n",
       "\n",
       "                           job_type  \n",
       "9120                  Self employed  \n",
       "4584   Formally employed Government  \n",
       "10727           Farming and Fishing  \n",
       "7951            Informally employed  \n",
       "3937            Farming and Fishing  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99c2ab",
   "metadata": {
    "papermill": {
     "duration": 0.011462,
     "end_time": "2022-06-03T02:54:55.283651",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.272189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.0. RandomForest - Pipeline\n",
    "\n",
    "parametros padrão utilizados inicialmente:\n",
    "\n",
    "Standard:\n",
    "(n_estimators=100, criterion='gini', max_depth=X, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=X, min_impurity_decrease=0.0, \n",
    "bootstrap=True, oob_score=False, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d3548c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.308963Z",
     "iopub.status.busy": "2022-06-03T02:54:55.308316Z",
     "iopub.status.idle": "2022-06-03T02:54:55.318867Z",
     "shell.execute_reply": "2022-06-03T02:54:55.318040Z"
    },
    "papermill": {
     "duration": 0.025653,
     "end_time": "2022-06-03T02:54:55.320955",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.295302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=2187)\n",
    "\n",
    "# parametros random forest (precisa do '__' antes de cada parametro para que o gridsearch entenda que são parametros do modelo\n",
    "params_rf = {}\n",
    "params_rf['model__criterion'] = ['entropy', 'gini']\n",
    "params_rf['model__n_estimators'] = [100, 150]\n",
    "params_rf['model__max_depth'] = [None,10,15]\n",
    "params_rf['model__class_weight'] = [None,'balanced', 'balanced_subsample']\n",
    "# params_rf['model__max_features'] = [None, 'sqrt']\n",
    "# params_rf['model__min_samples_split'] = [,10,]\n",
    "# params_rf['model__min_samples_leaf'] = [1,2,] \n",
    "params_rf['model'] = [rf]\n",
    "\n",
    "# StratifiedKFold para que cada fold mantenha a proporção do target\n",
    "cv_kfold= StratifiedKFold(n_splits=5,random_state=2187,shuffle=True)\n",
    "\n",
    "# colunas que passarão pelo OneHotEncoding\n",
    "onehot_columns = ['country', 'relationship_with_head', 'marital_status',  \n",
    "                  'education_level', 'cellphone_access', 'job_type' , 'location_type', \n",
    "                  'gender_of_respondent']\n",
    "\n",
    "# onehot_columns = ['marital_status','education_level', 'cellphone_access', 'job_type' , \n",
    "#                   'gender_of_respondent']\n",
    "\n",
    "# transformação - passthrough para que as colunas numericas que nao são transformadas pelo one hot passem reto\n",
    "# dentro de transformers, poderia ter colocado varias transformações diferentes para diferentes colunas\n",
    "encoders = ColumnTransformer(transformers= [('onehotencod', OneHotEncoder(), onehot_columns)],\n",
    "                             remainder = 'passthrough', \n",
    "                             verbose_feature_names_out = True,\n",
    "                             verbose=True)\n",
    "\n",
    "# pipeline - colunas transformadas E colunas numericas entram no pipeline para treinar o modelo\n",
    "# nos steps, poderia colocar SMOTE() em um dos passos, MinMaxScaler(), StandardScaler(), etc\n",
    "pipeline = Pipeline(steps = [('columntransformers', encoders),\n",
    "                             ('model', rf)],\n",
    "                    verbose=True)\n",
    "\n",
    "# criação do f1_score usando average 'micro'\n",
    "f1_score_micro = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Gridsearch - pega o pipeline, os parametros do modelo, a 'logica' de divisão kfold e treina modelos, \n",
    "# avaliando pelo f1 score e no final, retreinando o melhor modelo.\n",
    "grid_rf = GridSearchCV(pipeline, params_rf, \n",
    "                      cv = cv_kfold, \n",
    "                      scoring = f1_score_micro,\n",
    "                      return_train_score = True,\n",
    "                      refit=True,\n",
    "                      verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "044388c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.347697Z",
     "iopub.status.busy": "2022-06-03T02:54:55.347060Z",
     "iopub.status.idle": "2022-06-03T02:54:55.384962Z",
     "shell.execute_reply": "2022-06-03T02:54:55.384246Z"
    },
    "papermill": {
     "duration": 0.054289,
     "end_time": "2022-06-03T02:54:55.387185",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.332896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transforma y em 0 e 1 \n",
    "target_encod = LabelBinarizer() \n",
    "y_train = target_encod.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "363d0f93",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-03T02:54:55.412977Z",
     "iopub.status.busy": "2022-06-03T02:54:55.412343Z",
     "iopub.status.idle": "2022-06-03T03:03:42.143531Z",
     "shell.execute_reply": "2022-06-03T03:03:42.142260Z"
    },
    "papermill": {
     "duration": 526.74714,
     "end_time": "2022-06-03T03:03:42.146201",
     "exception": false,
     "start_time": "2022-06-03T02:54:55.399061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.871) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.7s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.866) total time=   2.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.864) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.852) total time=   2.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.863) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.872) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.864) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.865) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.853) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.863) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.904, test=0.887) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.905, test=0.883) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.905, test=0.886) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.906, test=0.881) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.904, test=0.885) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.905, test=0.888) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.905, test=0.883) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.905, test=0.884) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.906, test=0.881) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.904, test=0.883) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.942, test=0.883) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.0s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.943, test=0.882) total time=   2.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.0s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.945, test=0.879) total time=   2.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.947, test=0.874) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.943, test=0.883) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.943, test=0.886) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.944, test=0.880) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.945, test=0.878) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.946, test=0.874) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.942, test=0.883) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.869) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.865) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.7s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.865) total time=   2.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.991, test=0.851) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.860) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.868) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.866) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.863) total time=   4.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.991, test=0.850) total time=   4.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.863) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.907, test=0.886) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.908, test=0.883) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.910, test=0.882) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.909, test=0.880) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.905, test=0.883) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.907, test=0.886) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.907, test=0.884) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.909, test=0.883) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.7s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.908, test=0.881) total time=   1.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.905, test=0.885) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.945, test=0.883) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.946, test=0.880) total time=   2.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.947, test=0.880) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.947, test=0.871) total time=   2.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.946, test=0.879) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.945, test=0.885) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.946, test=0.880) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.947, test=0.879) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.947, test=0.871) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=None, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.946, test=0.880) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.9s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.865) total time=   3.0s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.861) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.9s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.863) total time=   3.0s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.9s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.846) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.9s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.857) total time=   3.0s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.4s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.989, test=0.866) total time=   4.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.865) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.4s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.862) total time=   4.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.847) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.858) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.854, test=0.823) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.851, test=0.825) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.854, test=0.833) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.862, test=0.809) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.846, test=0.811) total time=   1.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.857, test=0.828) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.851, test=0.828) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.852, test=0.832) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.9s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.862, test=0.805) total time=   2.0s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.844, test=0.807) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.942, test=0.860) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.938, test=0.855) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.940, test=0.851) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.950, test=0.843) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.936, test=0.842) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.939, test=0.857) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.937, test=0.862) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.942, test=0.852) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.951, test=0.845) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.937, test=0.840) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.9s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.865) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.859) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.862) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.847) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.857) total time=   2.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.989, test=0.862) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.863) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.860) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.847) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.3s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.857) total time=   4.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.858, test=0.825) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.858, test=0.825) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.853, test=0.823) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.866, test=0.807) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.851, test=0.813) total time=   1.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.857, test=0.826) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.855, test=0.825) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.855, test=0.826) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.867, test=0.804) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.850, test=0.816) total time=   1.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.947, test=0.865) total time=   2.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.938, test=0.862) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.946, test=0.850) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.952, test=0.844) total time=   2.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.940, test=0.838) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.946, test=0.860) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.939, test=0.860) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.946, test=0.850) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.953, test=0.843) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.937, test=0.838) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.866) total time=   3.3s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.859) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.862) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.845) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.854) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.989, test=0.866) total time=   4.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.859) total time=   4.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.861) total time=   4.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.844) total time=   4.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.855) total time=   4.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.850, test=0.817) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.850, test=0.825) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.852, test=0.833) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.865, test=0.811) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=100;, score=(train=0.838, test=0.807) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.850, test=0.813) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.848, test=0.824) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.854, test=0.829) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.864, test=0.807) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=10, model__n_estimators=150;, score=(train=0.840, test=0.807) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.942, test=0.860) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.4s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.935, test=0.853) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.939, test=0.850) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.947, test=0.840) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=100;, score=(train=0.934, test=0.840) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.6s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.942, test=0.857) total time=   3.7s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.933, test=0.854) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.941, test=0.850) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.947, test=0.843) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=entropy, model__max_depth=15, model__n_estimators=150;, score=(train=0.934, test=0.841) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.865) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.860) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.990, test=0.859) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.0s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.989, test=0.844) total time=   3.1s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.2s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=100;, score=(train=0.988, test=0.852) total time=   3.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.989, test=0.867) total time=   4.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.6s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.863) total time=   4.7s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.7s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.860) total time=   4.8s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.6s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.990, test=0.846) total time=   4.7s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   4.8s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=None, model__n_estimators=150;, score=(train=0.988, test=0.854) total time=   4.9s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.851, test=0.817) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.847, test=0.828) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.855, test=0.832) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.870, test=0.818) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=100;, score=(train=0.850, test=0.814) total time=   1.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.851, test=0.817) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.849, test=0.823) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.855, test=0.830) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.868, test=0.813) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.1s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=10, model__n_estimators=150;, score=(train=0.850, test=0.814) total time=   2.2s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.4s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.944, test=0.860) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.937, test=0.862) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.3s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.943, test=0.853) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.4s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.952, test=0.840) total time=   2.4s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   2.4s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=100;, score=(train=0.937, test=0.840) total time=   2.5s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 1/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.948, test=0.859) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 2/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.937, test=0.856) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 3/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.948, test=0.851) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.5s\n",
      "[CV 4/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.953, test=0.841) total time=   3.6s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   3.6s\n",
      "[CV 5/5] END model=RandomForestClassifier(random_state=2187), model__class_weight=balanced_subsample, model__criterion=gini, model__max_depth=15, model__n_estimators=150;, score=(train=0.939, test=0.843) total time=   3.7s\n",
      "[ColumnTransformer] ... (1 of 2) Processing onehotencod, total=   0.0s\n",
      "[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 1 of 2) Processing columntransformers, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=2187, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('columntransformers',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('onehotencod',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['country',\n",
       "                                                                          'relationship_with_head',\n",
       "                                                                          'marital_status',\n",
       "                                                                          'education_level',\n",
       "                                                                          'cellphone_access',\n",
       "                                                                          'job_type',\n",
       "                                                                          'location_type',\n",
       "                                                                          'gender_of_respondent']...\n",
       "                                verbose=True),\n",
       "             param_grid={'model': [RandomForestClassifier(criterion='entropy',\n",
       "                                                          max_depth=10,\n",
       "                                                          random_state=2187)],\n",
       "                         'model__class_weight': [None, 'balanced',\n",
       "                                                 'balanced_subsample'],\n",
       "                         'model__criterion': ['entropy', 'gini'],\n",
       "                         'model__max_depth': [None, 10, 15],\n",
       "                         'model__n_estimators': [100, 150]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(f1_score, average=micro), verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit na grid\n",
    "# .ravel() devido à warning\n",
    "grid_rf.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6129ef27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:42.228674Z",
     "iopub.status.busy": "2022-06-03T03:03:42.228230Z",
     "iopub.status.idle": "2022-06-03T03:03:42.235129Z",
     "shell.execute_reply": "2022-06-03T03:03:42.234125Z"
    },
    "papermill": {
     "duration": 0.051154,
     "end_time": "2022-06-03T03:03:42.237300",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.186146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RandomForestClassifier(criterion='entropy', max_depth=10, random_state=2187),\n",
       " 'model__class_weight': None,\n",
       " 'model__criterion': 'entropy',\n",
       " 'model__max_depth': 10,\n",
       " 'model__n_estimators': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quais os parametros do melhor modelo encontrado\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc1698d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:42.315958Z",
     "iopub.status.busy": "2022-06-03T03:03:42.315500Z",
     "iopub.status.idle": "2022-06-03T03:03:42.321761Z",
     "shell.execute_reply": "2022-06-03T03:03:42.320781Z"
    },
    "papermill": {
     "duration": 0.047801,
     "end_time": "2022-06-03T03:03:42.323799",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.275998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884488900987915"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qual o score do melhor modelo\n",
    "grid_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7d0165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:42.400402Z",
     "iopub.status.busy": "2022-06-03T03:03:42.399998Z",
     "iopub.status.idle": "2022-06-03T03:03:42.498341Z",
     "shell.execute_reply": "2022-06-03T03:03:42.497407Z"
    },
    "papermill": {
     "duration": 0.139528,
     "end_time": "2022-06-03T03:03:42.500524",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.360996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821195806177388"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checando o score do modelo encontrado pelo gridsearch na validação\n",
    "y_val = target_encod.transform(y_val)\n",
    "grid_rf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c16ceb",
   "metadata": {
    "papermill": {
     "duration": 0.036197,
     "end_time": "2022-06-03T03:03:42.573463",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.537266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.0. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fa3ec87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:42.649070Z",
     "iopub.status.busy": "2022-06-03T03:03:42.648634Z",
     "iopub.status.idle": "2022-06-03T03:03:42.724415Z",
     "shell.execute_reply": "2022-06-03T03:03:42.723321Z"
    },
    "papermill": {
     "duration": 0.11677,
     "end_time": "2022-06-03T03:03:42.727344",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.610574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>2017</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Farming and Fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  year location_type cellphone_access  household_size  \\\n",
       "0    Rwanda  2016         Rural              Yes               7   \n",
       "1    Rwanda  2016         Rural              Yes               3   \n",
       "2    Rwanda  2016         Urban              Yes               3   \n",
       "3  Tanzania  2017         Urban              Yes               1   \n",
       "4    Rwanda  2016         Rural              Yes               3   \n",
       "\n",
       "   age_of_respondent gender_of_respondent relationship_with_head  \\\n",
       "0                 40                 Male      Head of Household   \n",
       "1                 24                 Male                  Child   \n",
       "2                 25               Female                 Spouse   \n",
       "3                 35               Female      Head of Household   \n",
       "4                 60                 Male      Head of Household   \n",
       "\n",
       "            marital_status      education_level             job_type  \n",
       "0  Married/Living together  No formal education  Informally employed  \n",
       "1     Single/Never Married  Secondary education  Farming and Fishing  \n",
       "2  Married/Living together    Primary education  Farming and Fishing  \n",
       "3  Married/Living together    Primary education        Self employed  \n",
       "4  Married/Living together    Primary education  Farming and Fishing  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = pd.read_csv('/kaggle/input/inclusao-financeira-na-africa/test.csv')\n",
    "\n",
    "# drop same columns as the train dataset\n",
    "# teste_clean = teste.drop(['uniqueid', 'uid'], axis=1)\n",
    "teste_clean_dropped = teste.drop(['uniqueid', 'uid'], axis=1)\n",
    "\n",
    "teste_clean_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76820169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:42.807752Z",
     "iopub.status.busy": "2022-06-03T03:03:42.807316Z",
     "iopub.status.idle": "2022-06-03T03:03:43.020337Z",
     "shell.execute_reply": "2022-06-03T03:03:43.019272Z"
    },
    "papermill": {
     "duration": 0.255973,
     "end_time": "2022-06-03T03:03:43.022601",
     "exception": false,
     "start_time": "2022-06-03T03:03:42.766628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict com o modelo treinado\n",
    "bank_account = grid_rf.predict(teste_clean_dropped)\n",
    "\n",
    "# dataframe com as predições\n",
    "submission = pd.DataFrame(bank_account, columns=['bank_account'])\n",
    "\n",
    "# transforming the prediction data\n",
    "submission_words = submission.bank_account.apply(lambda x: 'Yes' if x==1 else 'No' )\n",
    "\n",
    "# concatenando com o teste\n",
    "submission2 = pd.concat([teste.uid, submission_words],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d1e8f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:43.102245Z",
     "iopub.status.busy": "2022-06-03T03:03:43.101390Z",
     "iopub.status.idle": "2022-06-03T03:03:43.110798Z",
     "shell.execute_reply": "2022-06-03T03:03:43.110160Z"
    },
    "papermill": {
     "duration": 0.052128,
     "end_time": "2022-06-03T03:03:43.112687",
     "exception": false,
     "start_time": "2022-06-03T03:03:43.060559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rwanda_uniqueid_625</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rwanda_uniqueid_1561</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rwanda_uniqueid_4806</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanzania_uniqueid_4902</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rwanda_uniqueid_980</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      uid bank_account\n",
       "0     Rwanda_uniqueid_625           No\n",
       "1    Rwanda_uniqueid_1561           No\n",
       "2    Rwanda_uniqueid_4806           No\n",
       "3  Tanzania_uniqueid_4902           No\n",
       "4     Rwanda_uniqueid_980           No"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf4850b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T03:03:43.191066Z",
     "iopub.status.busy": "2022-06-03T03:03:43.190067Z",
     "iopub.status.idle": "2022-06-03T03:03:43.227850Z",
     "shell.execute_reply": "2022-06-03T03:03:43.226835Z"
    },
    "papermill": {
     "duration": 0.078567,
     "end_time": "2022-06-03T03:03:43.230411",
     "exception": false,
     "start_time": "2022-06-03T03:03:43.151844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission2.to_csv('../submission4.csv',index=False) #gridsearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 541.585142,
   "end_time": "2022-06-03T03:03:43.994575",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-03T02:54:42.409433",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
